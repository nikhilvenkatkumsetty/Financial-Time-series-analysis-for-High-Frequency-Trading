{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"DeepLOB.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zGxFciRJqFCD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618213914571,"user_tz":-240,"elapsed":44151,"user":{"displayName":"Amith Bhat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQuvfvCgqUqQhsgnp6JrAz2KeBJn7adBjPacG6Vw=s64","userId":"11247628634889548034"}},"outputId":"d83dde02-0019-4f09-f00b-42302c747537"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-x9IDyuexIeE","executionInfo":{"status":"ok","timestamp":1618214825545,"user_tz":-240,"elapsed":1571,"user":{"displayName":"Amith Bhat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQuvfvCgqUqQhsgnp6JrAz2KeBJn7adBjPacG6Vw=s64","userId":"11247628634889548034"}}},"source":["# load packages\n","import pandas as pd\n","import gc\n","import tensorflow as tf\n","import pickle\n","import numpy as np\n","import keras\n","from keras import backend as K\n","from keras.models import load_model, Model\n","from keras.layers import Flatten, Dense, Dropout, Activation, Input, LSTM, Reshape, Conv2D, MaxPooling2D\n","from keras.optimizers import Adam\n","from keras.layers.advanced_activations import LeakyReLU\n","\n","from keras.utils import np_utils\n","import matplotlib.pyplot as plt\n","\n","# set random seeds\n","np.random.seed(1)\n","tf.random.set_seed(2)\n"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZUBMoMqxIeE"},"source":["# Data preparation\n"]},{"cell_type":"code","metadata":{"id":"XqyJcOObxIeF","executionInfo":{"status":"ok","timestamp":1618214825844,"user_tz":-240,"elapsed":1856,"user":{"displayName":"Amith Bhat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQuvfvCgqUqQhsgnp6JrAz2KeBJn7adBjPacG6Vw=s64","userId":"11247628634889548034"}}},"source":["def prepare_x(data):\n","    df1 = data[:40, :].T\n","    return np.array(df1)\n","\n","def get_label(data):\n","    lob = data[-5:, :].T\n","    return lob\n","\n","def data_classification(X, Y, T):\n","    [N, D] = X.shape\n","    df = np.array(X)\n","\n","    dY = np.array(Y)\n","\n","    dataY = dY[T - 1:N]\n","\n","    dataX = np.zeros((N - T + 1, T, D))\n","    for i in range(T, N + 1):\n","        dataX[i - T] = df[i - T:i, :]\n","\n","    return dataX.reshape(dataX.shape + (1,)), dataY"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUkt07imxIeG","executionInfo":{"status":"ok","timestamp":1618214861080,"user_tz":-240,"elapsed":37088,"user":{"displayName":"Amith Bhat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQuvfvCgqUqQhsgnp6JrAz2KeBJn7adBjPacG6Vw=s64","userId":"11247628634889548034"}}},"source":["dec_train = np.loadtxt('/content/drive/MyDrive/College/6th sem/DA/DA Mini Project/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_7.txt')\n","dec_test3 = np.loadtxt('/content/drive/MyDrive/College/6th sem/DA/DA Mini Project/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_7.txt')\n","dec_test4 = np.loadtxt('/content/drive/MyDrive/College/6th sem/DA/DA Mini Project/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_8.txt')\n","dec_test5 = np.loadtxt('/content/drive/MyDrive/College/6th sem/DA/DA Mini Project/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_9.txt')\n","dec_test = np.hstack((dec_test3, dec_test4, dec_test5))\n","del dec_test3\n","del dec_test4\n","del dec_test5\n","gc.collect()\n","\n","# extract limit order book data from the FI-2010 dataset\n","train_lob = prepare_x(dec_train)\n","test_lob = prepare_x(dec_test)\n","\n","# extract label from the FI-2010 dataset\n","train_label = get_label(dec_train)\n","test_label = get_label(dec_test)\n","\n","# prepare training data. We feed past 100 observations into our algorithms and choose the prediction horizon. \n","trainX_CNN, trainY_CNN = data_classification(train_lob, train_label, T=10)\n","trainY_CNN = trainY_CNN[:,3] - 1\n","trainY_CNN = np_utils.to_categorical(trainY_CNN, 3)\n","\n","# prepare test data.\n","testX_CNN, testY_CNN = data_classification(test_lob, test_label, T=10)\n","testY_CNN = testY_CNN[:,3] - 1\n","testY_CNN = np_utils.to_categorical(testY_CNN, 3)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fe7jQoqBxIeH"},"source":["# Model Architecture\n"]},{"cell_type":"code","metadata":{"id":"aeyyNSlhxIeH","executionInfo":{"status":"ok","timestamp":1618218408637,"user_tz":-240,"elapsed":1450,"user":{"displayName":"Amith Bhat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQuvfvCgqUqQhsgnp6JrAz2KeBJn7adBjPacG6Vw=s64","userId":"11247628634889548034"}}},"source":["def create_deeplob(T, NF, number_of_lstm):\n","    input_lmd = Input(shape=(T, NF, 1))\n","    \n","    # build the convolutional block\n","    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(input_lmd)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.05)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.05)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.05)(conv_first1)\n","\n","    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.05)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.05)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.05)(conv_first1)\n","\n","    conv_first1 = Conv2D(32, (1, 10))(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.05)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.05)(conv_first1)\n","    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n","    conv_first1 = keras.layers.LeakyReLU(alpha=0.05)(conv_first1)\n","    \n","    # build the inception module\n","    convsecond_1 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n","    convsecond_1 = keras.layers.LeakyReLU(alpha=0.05)(convsecond_1)\n","    convsecond_1 = Conv2D(64, (3, 1), padding='same')(convsecond_1)\n","    convsecond_1 = keras.layers.LeakyReLU(alpha=0.05)(convsecond_1)\n","\n","    convsecond_2 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n","    convsecond_2 = keras.layers.LeakyReLU(alpha=0.05)(convsecond_2)\n","    convsecond_2 = Conv2D(64, (5, 1), padding='same')(convsecond_2)\n","    convsecond_2 = keras.layers.LeakyReLU(alpha=0.05)(convsecond_2)\n","\n","    convsecond_3 = MaxPooling2D((3, 1), strides=(1, 1), padding='same')(conv_first1)\n","    convsecond_3 = Conv2D(64, (1, 1), padding='same')(convsecond_3)\n","    convsecond_3 = keras.layers.LeakyReLU(alpha=0.05)(convsecond_3)\n","    \n","    convsecond_output = keras.layers.concatenate([convsecond_1, convsecond_2, convsecond_3], axis=3)\n","    conv_reshape = Reshape((int(convsecond_output.shape[1]), int(convsecond_output.shape[3])))(convsecond_output)\n","\n","    # build the last LSTM layer\n","    conv_lstm = LSTM(number_of_lstm)(conv_reshape)\n","\n","    # build the output layer\n","    out = Dense(3, activation='softmax')(conv_lstm)\n","    model = Model(inputs=input_lmd, outputs=out)\n","    adam = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1)\n","    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","deeplob = create_deeplob(10, 40, 64)\n"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z2L5A0ZSxIeL"},"source":["# Model Training and Testing"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"aTEt9q_4xIeN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618221766579,"user_tz":-240,"elapsed":3339571,"user":{"displayName":"Amith Bhat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQuvfvCgqUqQhsgnp6JrAz2KeBJn7adBjPacG6Vw=s64","userId":"11247628634889548034"}},"outputId":"46bc9b0b-8d9b-47d3-c2db-d2c84fec0fd8"},"source":["deeplob.fit(trainX_CNN, trainY_CNN, epochs=100, batch_size=64, verbose=2, validation_data=(testX_CNN, testY_CNN))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","3981/3981 - 36s - loss: 1.0969 - accuracy: 0.3452 - val_loss: 1.1064 - val_accuracy: 0.3762\n","Epoch 2/100\n","3981/3981 - 33s - loss: 1.0852 - accuracy: 0.3796 - val_loss: 1.0529 - val_accuracy: 0.4926\n","Epoch 3/100\n","3981/3981 - 33s - loss: 0.9753 - accuracy: 0.4711 - val_loss: 0.8091 - val_accuracy: 0.6003\n","Epoch 4/100\n","3981/3981 - 33s - loss: 0.8944 - accuracy: 0.5172 - val_loss: 0.7826 - val_accuracy: 0.6072\n","Epoch 5/100\n","3981/3981 - 33s - loss: 0.8795 - accuracy: 0.5271 - val_loss: 0.7658 - val_accuracy: 0.6100\n","Epoch 6/100\n","3981/3981 - 33s - loss: 0.8696 - accuracy: 0.5318 - val_loss: 0.7716 - val_accuracy: 0.6066\n","Epoch 7/100\n","3981/3981 - 34s - loss: 0.8641 - accuracy: 0.5352 - val_loss: 0.7583 - val_accuracy: 0.6149\n","Epoch 8/100\n","3981/3981 - 34s - loss: 0.8592 - accuracy: 0.5389 - val_loss: 0.7701 - val_accuracy: 0.6215\n","Epoch 9/100\n","3981/3981 - 33s - loss: 0.8562 - accuracy: 0.5428 - val_loss: 0.7759 - val_accuracy: 0.6059\n","Epoch 10/100\n","3981/3981 - 33s - loss: 0.8540 - accuracy: 0.5462 - val_loss: 0.7701 - val_accuracy: 0.6313\n","Epoch 11/100\n","3981/3981 - 33s - loss: 0.8506 - accuracy: 0.5507 - val_loss: 0.7454 - val_accuracy: 0.6423\n","Epoch 12/100\n","3981/3981 - 33s - loss: 0.8486 - accuracy: 0.5570 - val_loss: 0.7448 - val_accuracy: 0.6445\n","Epoch 13/100\n","3981/3981 - 33s - loss: 0.8446 - accuracy: 0.5709 - val_loss: 0.7492 - val_accuracy: 0.6550\n","Epoch 14/100\n","3981/3981 - 33s - loss: 0.8328 - accuracy: 0.5965 - val_loss: 0.7248 - val_accuracy: 0.6893\n","Epoch 15/100\n","3981/3981 - 33s - loss: 0.7959 - accuracy: 0.6362 - val_loss: 0.6983 - val_accuracy: 0.7048\n","Epoch 16/100\n","3981/3981 - 33s - loss: 0.7749 - accuracy: 0.6529 - val_loss: 0.6810 - val_accuracy: 0.7155\n","Epoch 17/100\n","3981/3981 - 33s - loss: 0.7581 - accuracy: 0.6652 - val_loss: 0.6640 - val_accuracy: 0.7253\n","Epoch 18/100\n","3981/3981 - 33s - loss: 0.7386 - accuracy: 0.6783 - val_loss: 0.6478 - val_accuracy: 0.7363\n","Epoch 19/100\n","3981/3981 - 33s - loss: 0.7161 - accuracy: 0.6933 - val_loss: 0.6370 - val_accuracy: 0.7458\n","Epoch 20/100\n","3981/3981 - 33s - loss: 0.6930 - accuracy: 0.7073 - val_loss: 0.6217 - val_accuracy: 0.7548\n","Epoch 21/100\n","3981/3981 - 33s - loss: 0.6743 - accuracy: 0.7184 - val_loss: 0.6135 - val_accuracy: 0.7577\n","Epoch 22/100\n","3981/3981 - 33s - loss: 0.6616 - accuracy: 0.7257 - val_loss: 0.6019 - val_accuracy: 0.7663\n","Epoch 23/100\n","3981/3981 - 33s - loss: 0.6525 - accuracy: 0.7308 - val_loss: 0.6060 - val_accuracy: 0.7647\n","Epoch 24/100\n","3981/3981 - 33s - loss: 0.6446 - accuracy: 0.7341 - val_loss: 0.6069 - val_accuracy: 0.7621\n","Epoch 25/100\n","3981/3981 - 33s - loss: 0.6381 - accuracy: 0.7379 - val_loss: 0.5949 - val_accuracy: 0.7671\n","Epoch 26/100\n","3981/3981 - 34s - loss: 0.6324 - accuracy: 0.7414 - val_loss: 0.5942 - val_accuracy: 0.7716\n","Epoch 27/100\n","3981/3981 - 33s - loss: 0.6272 - accuracy: 0.7434 - val_loss: 0.5887 - val_accuracy: 0.7732\n","Epoch 28/100\n","3981/3981 - 34s - loss: 0.6235 - accuracy: 0.7453 - val_loss: 0.6007 - val_accuracy: 0.7687\n","Epoch 29/100\n","3981/3981 - 33s - loss: 0.6184 - accuracy: 0.7470 - val_loss: 0.5804 - val_accuracy: 0.7759\n","Epoch 30/100\n","3981/3981 - 33s - loss: 0.6153 - accuracy: 0.7492 - val_loss: 0.5833 - val_accuracy: 0.7738\n","Epoch 31/100\n","3981/3981 - 33s - loss: 0.6124 - accuracy: 0.7504 - val_loss: 0.5784 - val_accuracy: 0.7777\n","Epoch 32/100\n","3981/3981 - 33s - loss: 0.6091 - accuracy: 0.7514 - val_loss: 0.5768 - val_accuracy: 0.7770\n","Epoch 33/100\n","3981/3981 - 33s - loss: 0.6060 - accuracy: 0.7536 - val_loss: 0.5973 - val_accuracy: 0.7692\n","Epoch 34/100\n","3981/3981 - 33s - loss: 0.6029 - accuracy: 0.7551 - val_loss: 0.5778 - val_accuracy: 0.7787\n","Epoch 35/100\n","3981/3981 - 33s - loss: 0.6005 - accuracy: 0.7557 - val_loss: 0.5808 - val_accuracy: 0.7779\n","Epoch 36/100\n","3981/3981 - 34s - loss: 0.5971 - accuracy: 0.7578 - val_loss: 0.6024 - val_accuracy: 0.7699\n","Epoch 37/100\n","3981/3981 - 33s - loss: 0.5948 - accuracy: 0.7582 - val_loss: 0.5790 - val_accuracy: 0.7764\n","Epoch 38/100\n","3981/3981 - 33s - loss: 0.5925 - accuracy: 0.7589 - val_loss: 0.5699 - val_accuracy: 0.7805\n","Epoch 39/100\n","3981/3981 - 33s - loss: 0.5897 - accuracy: 0.7603 - val_loss: 0.5755 - val_accuracy: 0.7790\n","Epoch 40/100\n","3981/3981 - 33s - loss: 0.5875 - accuracy: 0.7614 - val_loss: 0.5713 - val_accuracy: 0.7816\n","Epoch 41/100\n","3981/3981 - 33s - loss: 0.5859 - accuracy: 0.7623 - val_loss: 0.5792 - val_accuracy: 0.7766\n","Epoch 42/100\n","3981/3981 - 33s - loss: 0.5834 - accuracy: 0.7635 - val_loss: 0.5867 - val_accuracy: 0.7733\n","Epoch 43/100\n","3981/3981 - 33s - loss: 0.5814 - accuracy: 0.7644 - val_loss: 0.5731 - val_accuracy: 0.7811\n","Epoch 44/100\n","3981/3981 - 33s - loss: 0.5793 - accuracy: 0.7648 - val_loss: 0.5664 - val_accuracy: 0.7848\n","Epoch 45/100\n","3981/3981 - 34s - loss: 0.5776 - accuracy: 0.7656 - val_loss: 0.5685 - val_accuracy: 0.7841\n","Epoch 46/100\n","3981/3981 - 33s - loss: 0.5757 - accuracy: 0.7672 - val_loss: 0.5702 - val_accuracy: 0.7824\n","Epoch 47/100\n","3981/3981 - 34s - loss: 0.5733 - accuracy: 0.7677 - val_loss: 0.5686 - val_accuracy: 0.7838\n","Epoch 48/100\n","3981/3981 - 33s - loss: 0.5710 - accuracy: 0.7689 - val_loss: 0.5630 - val_accuracy: 0.7867\n","Epoch 49/100\n","3981/3981 - 33s - loss: 0.5694 - accuracy: 0.7693 - val_loss: 0.5629 - val_accuracy: 0.7865\n","Epoch 50/100\n","3981/3981 - 34s - loss: 0.5675 - accuracy: 0.7711 - val_loss: 0.5657 - val_accuracy: 0.7855\n","Epoch 51/100\n","3981/3981 - 34s - loss: 0.5660 - accuracy: 0.7707 - val_loss: 0.5602 - val_accuracy: 0.7878\n","Epoch 52/100\n","3981/3981 - 34s - loss: 0.5639 - accuracy: 0.7722 - val_loss: 0.5636 - val_accuracy: 0.7852\n","Epoch 53/100\n","3981/3981 - 34s - loss: 0.5625 - accuracy: 0.7722 - val_loss: 0.5673 - val_accuracy: 0.7831\n","Epoch 54/100\n","3981/3981 - 35s - loss: 0.5608 - accuracy: 0.7732 - val_loss: 0.5598 - val_accuracy: 0.7873\n","Epoch 55/100\n","3981/3981 - 34s - loss: 0.5596 - accuracy: 0.7742 - val_loss: 0.5763 - val_accuracy: 0.7814\n","Epoch 56/100\n","3981/3981 - 35s - loss: 0.5583 - accuracy: 0.7748 - val_loss: 0.5749 - val_accuracy: 0.7831\n","Epoch 57/100\n","3981/3981 - 35s - loss: 0.5556 - accuracy: 0.7760 - val_loss: 0.5634 - val_accuracy: 0.7849\n","Epoch 58/100\n","3981/3981 - 34s - loss: 0.5544 - accuracy: 0.7764 - val_loss: 0.5626 - val_accuracy: 0.7861\n","Epoch 59/100\n","3981/3981 - 34s - loss: 0.5528 - accuracy: 0.7775 - val_loss: 0.5651 - val_accuracy: 0.7860\n","Epoch 60/100\n","3981/3981 - 34s - loss: 0.5514 - accuracy: 0.7771 - val_loss: 0.5651 - val_accuracy: 0.7865\n","Epoch 61/100\n","3981/3981 - 34s - loss: 0.5502 - accuracy: 0.7783 - val_loss: 0.5633 - val_accuracy: 0.7879\n","Epoch 62/100\n","3981/3981 - 34s - loss: 0.5487 - accuracy: 0.7787 - val_loss: 0.5603 - val_accuracy: 0.7892\n","Epoch 63/100\n","3981/3981 - 34s - loss: 0.5465 - accuracy: 0.7795 - val_loss: 0.5607 - val_accuracy: 0.7867\n","Epoch 64/100\n","3981/3981 - 34s - loss: 0.5457 - accuracy: 0.7803 - val_loss: 0.5617 - val_accuracy: 0.7875\n","Epoch 65/100\n","3981/3981 - 34s - loss: 0.5437 - accuracy: 0.7807 - val_loss: 0.5840 - val_accuracy: 0.7774\n","Epoch 66/100\n","3981/3981 - 34s - loss: 0.5427 - accuracy: 0.7810 - val_loss: 0.5795 - val_accuracy: 0.7803\n","Epoch 67/100\n","3981/3981 - 33s - loss: 0.5410 - accuracy: 0.7822 - val_loss: 0.5651 - val_accuracy: 0.7879\n","Epoch 68/100\n","3981/3981 - 33s - loss: 0.5393 - accuracy: 0.7825 - val_loss: 0.5716 - val_accuracy: 0.7837\n","Epoch 69/100\n","3981/3981 - 33s - loss: 0.5385 - accuracy: 0.7834 - val_loss: 0.5693 - val_accuracy: 0.7857\n","Epoch 70/100\n","3981/3981 - 33s - loss: 0.5370 - accuracy: 0.7839 - val_loss: 0.5677 - val_accuracy: 0.7865\n","Epoch 71/100\n","3981/3981 - 33s - loss: 0.5356 - accuracy: 0.7841 - val_loss: 0.5669 - val_accuracy: 0.7859\n","Epoch 72/100\n","3981/3981 - 33s - loss: 0.5342 - accuracy: 0.7852 - val_loss: 0.5914 - val_accuracy: 0.7771\n","Epoch 73/100\n","3981/3981 - 33s - loss: 0.5328 - accuracy: 0.7861 - val_loss: 0.5735 - val_accuracy: 0.7831\n","Epoch 74/100\n","3981/3981 - 33s - loss: 0.5314 - accuracy: 0.7865 - val_loss: 0.5627 - val_accuracy: 0.7867\n","Epoch 75/100\n","3981/3981 - 33s - loss: 0.5306 - accuracy: 0.7862 - val_loss: 0.5752 - val_accuracy: 0.7828\n","Epoch 76/100\n","3981/3981 - 33s - loss: 0.5291 - accuracy: 0.7872 - val_loss: 0.5680 - val_accuracy: 0.7863\n","Epoch 77/100\n","3981/3981 - 33s - loss: 0.5282 - accuracy: 0.7879 - val_loss: 0.5789 - val_accuracy: 0.7819\n","Epoch 78/100\n","3981/3981 - 33s - loss: 0.5264 - accuracy: 0.7885 - val_loss: 0.5650 - val_accuracy: 0.7875\n","Epoch 79/100\n","3981/3981 - 33s - loss: 0.5253 - accuracy: 0.7893 - val_loss: 0.5671 - val_accuracy: 0.7857\n","Epoch 80/100\n","3981/3981 - 33s - loss: 0.5239 - accuracy: 0.7895 - val_loss: 0.5783 - val_accuracy: 0.7823\n","Epoch 81/100\n","3981/3981 - 33s - loss: 0.5230 - accuracy: 0.7898 - val_loss: 0.5684 - val_accuracy: 0.7861\n","Epoch 82/100\n","3981/3981 - 34s - loss: 0.5215 - accuracy: 0.7905 - val_loss: 0.5722 - val_accuracy: 0.7844\n","Epoch 83/100\n","3981/3981 - 33s - loss: 0.5198 - accuracy: 0.7916 - val_loss: 0.5847 - val_accuracy: 0.7796\n","Epoch 84/100\n","3981/3981 - 33s - loss: 0.5186 - accuracy: 0.7920 - val_loss: 0.5707 - val_accuracy: 0.7839\n","Epoch 85/100\n","3981/3981 - 33s - loss: 0.5176 - accuracy: 0.7921 - val_loss: 0.5759 - val_accuracy: 0.7834\n","Epoch 86/100\n","3981/3981 - 33s - loss: 0.5166 - accuracy: 0.7923 - val_loss: 0.5756 - val_accuracy: 0.7837\n","Epoch 87/100\n","3981/3981 - 33s - loss: 0.5157 - accuracy: 0.7933 - val_loss: 0.5683 - val_accuracy: 0.7872\n","Epoch 88/100\n","3981/3981 - 34s - loss: 0.5143 - accuracy: 0.7936 - val_loss: 0.5969 - val_accuracy: 0.7748\n","Epoch 89/100\n","3981/3981 - 33s - loss: 0.5134 - accuracy: 0.7941 - val_loss: 0.5797 - val_accuracy: 0.7833\n","Epoch 90/100\n","3981/3981 - 33s - loss: 0.5121 - accuracy: 0.7950 - val_loss: 0.5780 - val_accuracy: 0.7820\n","Epoch 91/100\n","3981/3981 - 33s - loss: 0.5109 - accuracy: 0.7955 - val_loss: 0.5846 - val_accuracy: 0.7805\n","Epoch 92/100\n","3981/3981 - 33s - loss: 0.5101 - accuracy: 0.7961 - val_loss: 0.5775 - val_accuracy: 0.7849\n","Epoch 93/100\n","3981/3981 - 33s - loss: 0.5087 - accuracy: 0.7958 - val_loss: 0.5823 - val_accuracy: 0.7834\n","Epoch 94/100\n","3981/3981 - 33s - loss: 0.5071 - accuracy: 0.7964 - val_loss: 0.5817 - val_accuracy: 0.7830\n","Epoch 95/100\n","3981/3981 - 33s - loss: 0.5065 - accuracy: 0.7974 - val_loss: 0.5794 - val_accuracy: 0.7833\n","Epoch 96/100\n","3981/3981 - 33s - loss: 0.5046 - accuracy: 0.7977 - val_loss: 0.5843 - val_accuracy: 0.7799\n","Epoch 97/100\n","3981/3981 - 33s - loss: 0.5036 - accuracy: 0.7986 - val_loss: 0.5915 - val_accuracy: 0.7802\n","Epoch 98/100\n","3981/3981 - 33s - loss: 0.5027 - accuracy: 0.7990 - val_loss: 0.6007 - val_accuracy: 0.7751\n","Epoch 99/100\n","3981/3981 - 33s - loss: 0.5020 - accuracy: 0.7996 - val_loss: 0.5877 - val_accuracy: 0.7805\n","Epoch 100/100\n","3981/3981 - 33s - loss: 0.5004 - accuracy: 0.7997 - val_loss: 0.5777 - val_accuracy: 0.7834\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f8025e93a90>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1acYnpi3llu7","executionInfo":{"status":"ok","timestamp":1618218269412,"user_tz":-240,"elapsed":7340,"user":{"displayName":"Amith Bhat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQuvfvCgqUqQhsgnp6JrAz2KeBJn7adBjPacG6Vw=s64","userId":"11247628634889548034"}},"outputId":"a432015a-0f5f-409c-a670-4bec2da5472e"},"source":["from sklearn.metrics import classification_report\n","\n","y_pred = deeplob.predict(testX_CNN, batch_size=64, verbose=2)\n","y_pred_bool = np.argmax(y_pred, axis=1)\n","\n","round_testy = np.argmax(testY_CNN, axis=1)\n","\n","print(classification_report(round_testy, y_pred_bool))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["2181/2181 - 6s\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.67      0.71     38464\n","           1       0.79      0.89      0.84     66002\n","           2       0.74      0.66      0.70     35112\n","\n","    accuracy                           0.77    139578\n","   macro avg       0.77      0.74      0.75    139578\n","weighted avg       0.77      0.77      0.77    139578\n","\n"],"name":"stdout"}]}]}